{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0518_classification_ViT_l32.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install vit-keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQA2i8Yr5rQ9","executionInfo":{"status":"ok","timestamp":1656054351066,"user_tz":-540,"elapsed":6682,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"ef4eb548-724d-4e31-90fe-20586d8ca46e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vit-keras\n","  Downloading vit_keras-0.1.0-py3-none-any.whl (24 kB)\n","Collecting validators\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vit-keras) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->vit-keras) (1.21.6)\n","Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->vit-keras) (4.4.2)\n","Building wheels for collected packages: validators\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=151443b69e77d345754bb445a9eaa7fc88ab556aa8de687796751f1177f9dc31\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built validators\n","Installing collected packages: validators, vit-keras\n","Successfully installed validators-0.20.0 vit-keras-0.1.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QGEaRu2Int1G"},"outputs":[],"source":["# Import Libraries\n","import warnings\n","warnings.filterwarnings('ignore')\n","import time\n","import numpy as np\n","import pandas as pd\n","pd.options.display.float_format = '{:.2f}'.format\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn"]},{"cell_type":"code","source":["# 모델의 reproducibility를 위해 학습 환경 및 random seed 고정\n","import numpy as np\n","import tensorflow as tf\n","import random\n","\n","seed_num = 256\n","np.random.seed(seed_num)\n","random.seed(seed_num)\n","tf.random.set_seed(seed_num)\n","\n","from keras import backend as K\n","\n","session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads = 1,\n","                                        inter_op_parallelism_threads = 1)\n","sess = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = session_conf)\n","K.set_session(sess)"],"metadata":{"id":"MxPnFzHasmQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 라이브러리 가져오기 \n","import itertools\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from keras import Sequential\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from keras.preprocessing.image import ImageDataGenerator\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n"],"metadata":{"id":"ACdXCtnjoL96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjDTI33ZoL7b","executionInfo":{"status":"ok","timestamp":1656054426900,"user_tz":-540,"elapsed":19433,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"08f0ca8f-3cbd-4bc8-dcc7-a0af15c4b73a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["x_train = np.load('/content/drive/Shareddrives/2022-1 KUBIG 음악추천시스템/melspectogram.npy')\n","x_train = np.concatenate([x_train[:200], x_train[400:]])"],"metadata":{"id":"xsfXNLV5oMA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target = []\n","for i in range(200):\n","  target.append(0)\n","for i in range(200):\n","  target.append(1)\n","for i in range(200):\n","  target.append(2)\n","for i in range(200):\n","  target.append(3)"],"metadata":{"id":"dwS5_TpDuz0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = np.array(target)"],"metadata":{"id":"p7J11399vEa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","cv2.resize(x_train[0], (256, 256), interpolation = cv2.INTER_LANCZOS4).shape\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","new = []\n","for i in range(800):\n","  scaler = StandardScaler()\n","  temp = scaler.fit_transform(x_train[i])\n","  new.append(cv2.resize(temp, (256, 256), interpolation = cv2.INTER_LANCZOS4))"],"metadata":{"id":"KFfRNx5AtKf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new2 = []\n","for i in range(800):\n","  new2.append(np.array([new[i], new[i], new[i]]))"],"metadata":{"id":"R8PMfmO7tN2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = np.array(new2)"],"metadata":{"id":"bini7odrvgpo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfuQVLcSwMgx","executionInfo":{"status":"ok","timestamp":1656054448031,"user_tz":-540,"elapsed":30,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"714b1170-c3a3-464b-9f16-523d0ea84535"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(800, 3, 256, 256)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["x_train = np.swapaxes(np.swapaxes(x_train, 1, 2), 2, 3)"],"metadata":{"id":"9Mvoz97zv16E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2ODt2Z20NzR","executionInfo":{"status":"ok","timestamp":1656054448032,"user_tz":-540,"elapsed":25,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"b334ac3d-bf9c-422d-e684-03efde0cdc64"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(800, 256, 256, 3)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"g_aCvZUu0QTI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, random_state = 256, test_size = 0.2)"],"metadata":{"id":"sV2fCKeK0fry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rCJHmcv96z1P","executionInfo":{"status":"ok","timestamp":1656054577294,"user_tz":-540,"elapsed":3224,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"299779a9-8d69-499d-9fc1-7489ad27955f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.17.1\n"]}]},{"cell_type":"code","source":["from vit_keras import vit, utils, visualize\n","\n","image_size = 256\n","\n","model = vit.vit_l32(\n","    image_size=image_size,\n","    activation='relu',\n","    pretrained=True,\n","    include_top=True,\n","    pretrained_top=False,\n","    classes=5\n",")"],"metadata":{"id":"llpgyzFP6B3_","executionInfo":{"status":"ok","timestamp":1656054610881,"user_tz":-540,"elapsed":30680,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f7604455-ea78-4345-f098-f23c29e64a5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-L_32_imagenet21k+imagenet2012.npz\n","1226661888/1226658854 [==============================] - 21s 0us/step\n","1226670080/1226658854 [==============================] - 21s 0us/step\n"]}]},{"cell_type":"code","source":["for layer in model.layers[:-1]:\n","    layer.trainable = False"],"metadata":{"id":"bx5LYbmY7G6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","model.compile(optimizer ='adamax',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","\n","print('Model Details are : ')\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oafQxbdteAI","executionInfo":{"status":"ok","timestamp":1656054626098,"user_tz":-540,"elapsed":700,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}},"outputId":"ba5ae0a6-93d1-41df-9688-9faf17cd4a88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Details are : \n","Model: \"vit-l32\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," embedding (Conv2D)          (None, 8, 8, 1024)        3146752   \n","                                                                 \n"," reshape (Reshape)           (None, 64, 1024)          0         \n","                                                                 \n"," class_token (ClassToken)    (None, 65, 1024)          1024      \n","                                                                 \n"," Transformer/posembed_input   (None, 65, 1024)         66560     \n"," (AddPositionEmbs)                                               \n","                                                                 \n"," Transformer/encoderblock_0   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_1   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_2   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_3   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_4   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_5   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_6   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_7   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_8   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_9   ((None, 65, 1024),       12596224  \n"," (TransformerBlock)           (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_10  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_11  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_12  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_13  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_14  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_15  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_16  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_17  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_18  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_19  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_20  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_21  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_22  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoderblock_23  ((None, 65, 1024),       12596224  \n","  (TransformerBlock)          (None, 16, None, None))            \n","                                                                 \n"," Transformer/encoder_norm (L  (None, 65, 1024)         2048      \n"," ayerNormalization)                                              \n","                                                                 \n"," ExtractToken (Lambda)       (None, 1024)              0         \n","                                                                 \n"," head (Dense)                (None, 5)                 5125      \n","                                                                 \n","=================================================================\n","Total params: 305,530,885\n","Trainable params: 305,530,885\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","\n","kfold = 5\n","skf = StratifiedKFold(n_splits = kfold, shuffle = True, random_state = 256)"],"metadata":{"id":"lf9hm9A5vzeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping  "],"metadata":{"id":"y6pR4FKJwRti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testpred = []\n","testprob = []\n","\n","for i, (train_index, val_index) in enumerate(skf.split(x_train, y_train)):\n","    \n","    print('[Fold %d/%d]' % (i + 1, kfold))\n","    \n","    \n","    trainx, validx = x_train[train_index], x_train[val_index]\n","    trainy, validy = y_train[train_index], y_train[val_index]\n","\n"," \n","    callbacks_list = [  \n","      ModelCheckpoint('/content/drive/MyDrive/musicrecommendation_transformerL{zero}.h5'.format(zero = i), monitor='val_accuracy', mode='max', verbose = 1, save_best_only = True),\n","      EarlyStopping(patience=8, verbose = 1),\n","      ReduceLROnPlateau(patience=4, verbose=1)\n","    ]  \n","\n","    ThisModel = model.fit(trainx, trainy, validation_data = (validx, validy), batch_size=32, epochs=100, callbacks=callbacks_list, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCLc8YiSvzgI","outputId":"e171283e-e824-4f99-f421-dcfa0bc1a774","executionInfo":{"status":"ok","timestamp":1656056164863,"user_tz":-540,"elapsed":1529891,"user":{"displayName":"‍박상준[ 학부재학 / 통계학과 ]","userId":"18258518088787550445"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Fold 1/5]\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1371 - accuracy: 0.2531\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to /content/drive/MyDrive/musicrecommendation_transformerL0.h5\n","20/20 [==============================] - 100s 4s/step - loss: 5.1371 - accuracy: 0.2531 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 2: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 30s 2s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 3: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 4: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 5: val_accuracy did not improve from 0.25000\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 6: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-04\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 7: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-04\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 8: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-04\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 9: val_accuracy did not improve from 0.25000\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-04\n","Epoch 9: early stopping\n","[Fold 2/5]\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to /content/drive/MyDrive/musicrecommendation_transformerL1.h5\n","20/20 [==============================] - 55s 3s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-05\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 2: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 32s 2s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-05\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 3: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-05\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 4: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 28s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-05\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 5: val_accuracy did not improve from 0.25000\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-05\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 6: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-06\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 7: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-06\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 8: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-06\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 9: val_accuracy did not improve from 0.25000\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-06\n","Epoch 9: early stopping\n","[Fold 3/5]\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to /content/drive/MyDrive/musicrecommendation_transformerL2.h5\n","20/20 [==============================] - 58s 3s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-07\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 2: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-07\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 3: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 30s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-07\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 4: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-07\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 5: val_accuracy did not improve from 0.25000\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-07\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 6: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-08\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 7: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-08\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 8: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-08\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 9: val_accuracy did not improve from 0.25000\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-08\n","Epoch 9: early stopping\n","[Fold 4/5]\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to /content/drive/MyDrive/musicrecommendation_transformerL3.h5\n","20/20 [==============================] - 55s 3s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-09\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 2: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-09\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 3: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 30s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-09\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 4: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-09\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 5: val_accuracy did not improve from 0.25000\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-09\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 6: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-10\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 7: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-10\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 8: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-10\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 9: val_accuracy did not improve from 0.25000\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-10\n","Epoch 9: early stopping\n","[Fold 5/5]\n","Epoch 1/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 1: val_accuracy improved from -inf to 0.25000, saving model to /content/drive/MyDrive/musicrecommendation_transformerL4.h5\n","20/20 [==============================] - 55s 3s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-11\n","Epoch 2/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 2: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 30s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-11\n","Epoch 3/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 3: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 30s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-11\n","Epoch 4/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 4: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 28s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-11\n","Epoch 5/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 5: val_accuracy did not improve from 0.25000\n","\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-11\n","Epoch 6/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 6: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-12\n","Epoch 7/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 7: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-12\n","Epoch 8/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 8: val_accuracy did not improve from 0.25000\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-12\n","Epoch 9/100\n","20/20 [==============================] - ETA: 0s - loss: 5.1281 - accuracy: 0.2500\n","Epoch 9: val_accuracy did not improve from 0.25000\n","\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n","20/20 [==============================] - 29s 1s/step - loss: 5.1281 - accuracy: 0.2500 - val_loss: 5.1281 - val_accuracy: 0.2500 - lr: 1.0000e-12\n","Epoch 9: early stopping\n"]}]},{"cell_type":"code","source":["testpred"],"metadata":{"id":"lfT05oJYxRWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testprob"],"metadata":{"id":"Dk3UsRQWxSmt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","  sum = 0\n","  sum_list = []\n","  for j in range(len(testpred[i])):\n","    if testpred[i][j] == y_test[j]:\n","      sum = sum + 1\n","  print(sum / len(testpred[1]) * 100)\n","  sum_list.append(sum / len(testpred[1]) * 100)"],"metadata":{"id":"O3yuzQRb6qPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(sum_list)"],"metadata":{"id":"YOkohHd71zqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"nKrFw_oU68Rj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_tpr_fpr(y_real, y_pred):\n","    '''\n","    Calculates the True Positive Rate (tpr) and the True Negative Rate (fpr) based on real and predicted observations\n","    \n","    Args:\n","        y_real: The list or series with the real classes\n","        y_pred: The list or series with the predicted classes\n","        \n","    Returns:\n","        tpr: The True Positive Rate of the classifier\n","        fpr: The False Positive Rate of the classifier\n","    '''\n","    \n","    # Calculates the confusion matrix and recover each element\n","    cm = confusion_matrix(y_real, y_pred)\n","    TN = cm[0, 0]\n","    FP = cm[0, 1]\n","    FN = cm[1, 0]\n","    TP = cm[1, 1]\n","    \n","    # Calculates tpr and fpr\n","    tpr =  TP/(TP + FN) # sensitivity - true positive rate\n","    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate\n","    \n","    return tpr, fpr"],"metadata":{"id":"0e9koCew7F6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_all_roc_coordinates(y_real, y_proba):\n","    '''\n","    Calculates all the ROC Curve coordinates (tpr and fpr) by considering each point as a treshold for the predicion of the class.\n","    \n","    Args:\n","        y_real: The list or series with the real classes.\n","        y_proba: The array with the probabilities for each class, obtained by using the `.predict_proba()` method.\n","        \n","    Returns:\n","        tpr_list: The list of TPRs representing each threshold.\n","        fpr_list: The list of FPRs representing each threshold.\n","    '''\n","    tpr_list = [0]\n","    fpr_list = [0]\n","    for i in range(len(y_proba)):\n","        threshold = y_proba[i]\n","        y_pred = y_proba >= threshold\n","        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)\n","        tpr_list.append(tpr)\n","        fpr_list.append(fpr)\n","    return tpr_list, fpr_list"],"metadata":{"id":"jGoaGjw0r1iu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_roc_curve_blue(tpr, fpr, scatter = True, ax = None):\n","    '''\n","    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n","    \n","    Args:\n","        tpr: The list of TPRs representing each coordinate.\n","        fpr: The list of FPRs representing each coordinate.\n","        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n","    '''\n","    if ax == None:\n","        plt.figure(figsize = (5, 5))\n","        ax = plt.axes()\n","    \n","    if scatter:\n","        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n","    sns.lineplot(x = fpr, y = tpr, ax = ax, ci=None, color='skyblue', alpha = 0.08)\n","    sns.lineplot(x = [0, 1], y = [0, 1], color = 'black', ax = ax, alpha = 0.05, linestyle='--')\n","    plt.xlim(-0.05, 1.05)\n","    plt.ylim(-0.05, 1.05)\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")"],"metadata":{"id":"NwAwpskir1ku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_roc_curve_red(tpr, fpr, scatter = True, ax = None):\n","    '''\n","    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n","    \n","    Args:\n","        tpr: The list of TPRs representing each coordinate.\n","        fpr: The list of FPRs representing each coordinate.\n","        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n","    '''\n","    if ax == None:\n","        plt.figure(figsize = (5, 5))\n","        ax = plt.axes()\n","    \n","    if scatter:\n","        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n","    sns.lineplot(x = fpr, y = tpr, ax = ax, ci=None, color='red', alpha = 0.08)\n","    sns.lineplot(x = [0, 1], y = [0, 1], color = 'black', ax = ax, alpha = 0.05, linestyle='--')\n","    plt.xlim(-0.05, 1.05)\n","    plt.ylim(-0.05, 1.05)\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")"],"metadata":{"id":"T_wwH464r1m5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_roc_curve_red_2(tpr, fpr, scatter = True, ax = None):\n","    '''\n","    Plots the ROC Curve by using the list of coordinates (tpr and fpr).\n","    \n","    Args:\n","        tpr: The list of TPRs representing each coordinate.\n","        fpr: The list of FPRs representing each coordinate.\n","        scatter: When True, the points used on the calculation will be plotted with the line (default = True).\n","    '''\n","    if ax == None:\n","        plt.figure(figsize = (5, 5))\n","        ax = plt.axes()\n","    \n","    if scatter:\n","        sns.scatterplot(x = fpr, y = tpr, ax = ax)\n","    sns.lineplot(x = fpr, y = tpr, ax = ax, ci=None, color='red', alpha = 1)\n","    plt.xlim(-0.05, 1.05)\n","    plt.ylim(-0.05, 1.05)\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")"],"metadata":{"id":"kVkUTlgRr1pD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = [0, 1, 2, 3, 4]\n","classes"],"metadata":{"id":"vAzzK4a0r1rQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes_names = ['Hip hop', 'Dance', 'Trot', 'Ballad', 'Rock']"],"metadata":{"id":"yAjnr8030jgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, roc_auc_score, auc\n","import seaborn as sns"],"metadata":{"id":"v0-_TckT0jia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"lFxHYCFJ2BfL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (12, 8))\n","roc_auc_ovr = {}\n","auc = []\n","    \n","for i in range(len(classes)):\n","    \n","    temptpr = []\n","    tempfpr = []\n","    \n","    for j in range(5):\n","\n","        c = classes[i]\n","\n","        df_aux = pd.DataFrame(y_test).copy()\n","        df_aux['class'] = [1 if y == c else 0 for y in y_test]\n","        df_aux['prob'] = np.array(testprob)[j][:, i]\n","        df_aux = df_aux.reset_index(drop = True)\n","\n","        ax_bottom = plt.subplot(2, 3, i+2)\n","        tpr, fpr = get_all_roc_coordinates(df_aux['class'], df_aux['prob'])\n","\n","\n","        temptpr.append(tpr)\n","        tempfpr.append(fpr)\n","        \n","        plot_roc_curve_red(tpr, fpr, scatter = False, ax = ax_bottom)\n","        \n","        \n","        ax_bottom.set_title(f\"ROC Curve OvR: {classes_names[c]} vs. Rest\")\n","\n","        auc.append(roc_auc_score(df_aux['class'], df_aux['prob']))\n","    \n","    temptpr = np.array(temptpr)\n","    tempfpr = np.array(tempfpr)\n","    \n","    num = 9 + i * 10\n","    prev = 9 + (i-1)*10\n","    plot_roc_curve_red_2(np.sort(np.array(pd.DataFrame(temptpr).mean())), np.sort(np.array(pd.DataFrame(tempfpr).mean())), scatter = False, ax = ax_bottom)\n","\n","    plt.tight_layout()"],"metadata":{"id":"COLGuHkG0jkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc[:5]"],"metadata":{"id":"7w2xMUW80jnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(auc[:5])"],"metadata":{"id":"4na3KqQj3Js2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc[5:10]"],"metadata":{"id":"RFDtxs2X0jqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(auc[5:10])"],"metadata":{"id":"ZZtkF7ns3L6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc[10:15]"],"metadata":{"id":"zRdATJV_0jrv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(auc[10:15])"],"metadata":{"id":"xE6BWNRg3P_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc[15:20]"],"metadata":{"id":"TZYx5cEf3Fz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(auc[15:20])"],"metadata":{"id":"2OpbKBg23Rns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["auc[20:25]"],"metadata":{"id":"oV1ZUaFy3F13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.mean(auc[20:25])"],"metadata":{"id":"kqviW2gL3TUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["totalauc = [np.mean(auc[:5]), np.mean(auc[5:10]), np.mean(auc[10:15]), np.mean(auc[15:20]), np.mean(auc[20:25])]\n","np.mean(totalauc)"],"metadata":{"id":"SQg0QkLy3U-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","\n","sens0 = []\n","spec0 = []\n","sens1 = []\n","spec1 = []\n","sens2 = []\n","spec2 = []\n","sens3 = []\n","spec3 = []\n","sens4 = []\n","spec4 = []\n","\n","for i in range(5):\n","    for l in [0, 1, 2, 3, 4]:\n","        prec, recall, _, _ = precision_recall_fscore_support(np.array(y_test) == l, testpred[i] == l, pos_label = True, average = None)\n","        if l == 0:\n","            sens0.append(recall[0])\n","            spec0.append(recall[1])\n","        elif l == 1:\n","            sens1.append(recall[0])\n","            spec1.append(recall[1])\n","        elif l == 2:\n","            sens2.append(recall[0])\n","            spec2.append(recall[1])\n","        elif l == 3:\n","            sens3.append(recall[0])\n","            spec3.append(recall[1])\n","        else:\n","            sens4.append(recall[0])\n","            spec4.append(recall[1])\n","            \n","df = [[np.mean(sens0), np.mean(spec0)], [np.mean(sens1), np.mean(spec1)], [np.mean(sens2), np.mean(spec2)], [np.mean(sens3), np.mean(spec3)], [np.mean(sens4), np.mean(spec4)]]\n","print(pd.DataFrame(df))\n","print(pd.DataFrame(df).mean(axis=0))"],"metadata":{"id":"JGGoLO243mLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## simplernn\n","## lstm\n","## gru\n","\n","## resnet50\n","## inception / xception\n","## senet (그냥...)\n","## vision transformer\n","\n","## cosine similiarity\n","## p-norm\n","\n","\n","## 1. 본인 장르 30개 더\n","## 2. 7788 / 상준 승은 지호 지우\n","## 3. 지호 지우 추천시스템 (함수 만들기) - cv 모델 느낌만\n","## 4. 상준 승은 다 하기"],"metadata":{"id":"9aWLdDi_7F9_"},"execution_count":null,"outputs":[]}]}